{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tachvault/python_libs/blob/main/Essential_library_functions_and_examples_of_matpl_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Okay, let's cover the essential Matplotlib functions and plotting styles commonly used in machine learning (ML) and deep learning (DL) workflows, along with examples.\n",
        "\n",
        "Matplotlib is the foundational data visualization library in Python. In ML/DL, it's crucial for:\n",
        "* Understanding data distributions.\n",
        "* Visualizing model performance during and after training (e.g., loss/accuracy curves).\n",
        "* Inspecting model predictions vs. actual values.\n",
        "* Visualizing datasets (especially images).\n",
        "* Presenting results (e.g., confusion matrices, feature importance).\n",
        "\n",
        "**Standard Import & Setup**"
      ],
      "metadata": {
        "id": "caScMBkg6JgF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np # Often used together to generate/manipulate data for plotting\n",
        "\n",
        "# Optional: Commonly used in Jupyter notebooks to display plots inline\n",
        "%matplotlib inline\n",
        "\n",
        "# Optional: Set a default figure size for better readability\n",
        "plt.rcParams['figure.figsize'] = (8, 5) # (width, height in inches)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "0oKJrObL6JgG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Core Concepts: Figure and Axes**\n",
        "\n",
        "* **Figure:** The whole window or page the plot is drawn on.\n",
        "* **Axes:** The area where data is plotted; a figure can contain multiple axes (subplots).\n",
        "\n",
        "You can use the `pyplot` interface (`plt.plot()`, `plt.title()`, etc.) for simple plots, or the more flexible object-oriented interface (creating `figure` and `axes` objects: `fig, ax = plt.subplots(); ax.plot(); ax.set_title()`), which is generally recommended, especially for multiple subplots.\n",
        "\n",
        "**1. Line Plots (`plt.plot()` / `ax.plot()`)**\n",
        "\n",
        "* **Use Case:** Plotting training/validation loss and accuracy over epochs, visualizing time series data, showing the relationship between two ordered variables."
      ],
      "metadata": {
        "id": "ZkxV7GSu6JgG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulate training history\n",
        "epochs = np.arange(1, 21)\n",
        "train_loss = 0.8 / epochs + np.random.randn(20) * 0.05\n",
        "val_loss = 0.9 / epochs + np.random.randn(20) * 0.08 + 0.05 # Slightly higher validation loss\n",
        "train_acc = 1 - (0.7 / epochs + np.random.randn(20) * 0.03)\n",
        "val_acc = 1 - (0.8 / epochs + np.random.randn(20) * 0.05)\n",
        "\n",
        "# --- Using Pyplot interface ---\n",
        "# plt.figure() # Create a new figure (optional for single plot)\n",
        "# plt.plot(epochs, train_loss, label='Training Loss', marker='o')\n",
        "# plt.plot(epochs, val_loss, label='Validation Loss', marker='x')\n",
        "# plt.title('Model Loss over Epochs (Pyplot)')\n",
        "# plt.xlabel('Epoch')\n",
        "# plt.ylabel('Loss')\n",
        "# plt.legend()\n",
        "# plt.grid(True)\n",
        "# plt.show() # Display the plot\n",
        "\n",
        "# --- Using Object-Oriented interface (better for customization/subplots) ---\n",
        "fig, ax1 = plt.subplots() # Create figure and one axes object\n",
        "\n",
        "# Plot loss on the first y-axis\n",
        "color = 'tab:red'\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Loss', color=color)\n",
        "ax1.plot(epochs, train_loss, color=color, linestyle='-', marker='o', label='Training Loss')\n",
        "ax1.plot(epochs, val_loss, color=color, linestyle='--', marker='x', label='Validation Loss')\n",
        "ax1.tick_params(axis='y', labelcolor=color)\n",
        "ax1.grid(True, axis='y') # Add horizontal grid lines for loss\n",
        "\n",
        "# Create a second y-axis sharing the same x-axis for accuracy\n",
        "ax2 = ax1.twinx()\n",
        "color = 'tab:blue'\n",
        "ax2.set_ylabel('Accuracy', color=color)\n",
        "ax2.plot(epochs, train_acc, color=color, linestyle='-', marker='s', label='Training Accuracy')\n",
        "ax2.plot(epochs, val_acc, color=color, linestyle='--', marker='^', label='Validation Accuracy')\n",
        "ax2.tick_params(axis='y', labelcolor=color)\n",
        "ax2.set_ylim(0, 1.1) # Set accuracy limits\n",
        "\n",
        "# Add titles and legends\n",
        "fig.suptitle('Model Training History (Object-Oriented)') # Overall title\n",
        "fig.legend(loc='upper center', bbox_to_anchor=(0.5, -0.01), ncol=2) # Combine legends below plot\n",
        "fig.tight_layout(rect=[0, 0.03, 1, 0.95]) # Adjust layout to prevent title overlap and make space for legend\n",
        "\n",
        "plt.show() # Display the plot"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "3qOKHd6-6JgG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Scatter Plots (`plt.scatter()` / `ax.scatter()`)**\n",
        "\n",
        "* **Use Case:** Visualizing the relationship between two features, comparing actual vs. predicted values in regression, visualizing clusters (e.g., after PCA or t-SNE), identifying outliers."
      ],
      "metadata": {
        "id": "0CVfgaIc6JgG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulate actual vs predicted values for regression\n",
        "np.random.seed(42)\n",
        "actual_values = np.random.rand(50) * 10\n",
        "predicted_values = actual_values + np.random.randn(50) * 1.5 # Predictions with some noise\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.scatter(actual_values, predicted_values, alpha=0.7, edgecolors='k', label='Data points')\n",
        "\n",
        "# Add a line representing perfect predictions (y=x)\n",
        "lims = [min(ax.get_xlim()[0], ax.get_ylim()[0]), max(ax.get_xlim()[1], ax.get_ylim()[1])]\n",
        "ax.plot(lims, lims, 'r--', alpha=0.75, zorder=0, label='Perfect Prediction') # zorder=0 puts line behind points\n",
        "\n",
        "ax.set_xlabel(\"Actual Values\")\n",
        "ax.set_ylabel(\"Predicted Values\")\n",
        "ax.set_title(\"Actual vs. Predicted Values in Regression\")\n",
        "ax.legend()\n",
        "ax.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# --- Example: Visualizing Clusters ---\n",
        "from sklearn.datasets import make_blobs # For generating sample cluster data\n",
        "X, y = make_blobs(n_samples=100, centers=3, n_features=2, random_state=42, cluster_std=1.0)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "scatter = ax.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis', edgecolors='k', alpha=0.8)\n",
        "ax.set_xlabel(\"Feature 1 (or PC1/t-SNE1)\")\n",
        "ax.set_ylabel(\"Feature 2 (or PC2/t-SNE2)\")\n",
        "ax.set_title(\"Data Clusters Visualization\")\n",
        "ax.legend(handles=scatter.legend_elements()[0], labels=['Cluster 0', 'Cluster 1', 'Cluster 2'])\n",
        "ax.grid(True)\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "gdmiokNq6JgG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Histograms (`plt.hist()` / `ax.hist()`)**\n",
        "\n",
        "* **Use Case:** Understanding the distribution of a single variable (feature values, prediction errors), checking for normality or skewness."
      ],
      "metadata": {
        "id": "5NtJALcg6JgH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulate prediction errors (ideally centered around zero)\n",
        "errors = np.random.randn(1000) * 5 # Normally distributed errors with std dev 5\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.hist(errors, bins=30, edgecolor='black', alpha=0.7) # bins controls number of bars\n",
        "ax.set_xlabel(\"Prediction Error\")\n",
        "ax.set_ylabel(\"Frequency\")\n",
        "ax.set_title(\"Distribution of Prediction Errors\")\n",
        "ax.axvline(errors.mean(), color='r', linestyle='dashed', linewidth=1, label=f'Mean: {errors.mean():.2f}')\n",
        "ax.axvline(0, color='k', linestyle='solid', linewidth=1, label='Zero Error')\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "r71bXYbk6JgH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Bar Charts (`plt.bar()` / `ax.bar()`)**\n",
        "\n",
        "* **Use Case:** Comparing metrics across different models, visualizing feature importance scores, showing class distributions."
      ],
      "metadata": {
        "id": "uatdANNz6JgH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulate feature importance scores\n",
        "features = ['Feature A', 'Feature B', 'Feature C', 'Feature D']\n",
        "importance = [0.45, 0.25, 0.15, 0.15]\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.bar(features, importance, color=['skyblue', 'lightcoral', 'lightgreen', 'gold'])\n",
        "ax.set_xlabel(\"Features\")\n",
        "ax.set_ylabel(\"Importance Score\")\n",
        "ax.set_title(\"Feature Importance\")\n",
        "ax.set_ylim(0, 0.5) # Adjust y-limit for better visualization\n",
        "# Add text labels on bars\n",
        "for i, v in enumerate(importance):\n",
        "    ax.text(i, v + 0.01, f\"{v:.2f}\", ha='center', va='bottom')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "FmcDC5zt6JgH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Image Display (`plt.imshow()` / `ax.imshow()`)**\n",
        "\n",
        "* **Use Case:** Displaying images from datasets (e.g., MNIST, CIFAR), visualizing filters or activation maps in Convolutional Neural Networks (CNNs)."
      ],
      "metadata": {
        "id": "xT4Z_bel6JgH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulate a grayscale image (e.g., MNIST digit) - 28x28 pixels\n",
        "image_gray = np.random.rand(28, 28)\n",
        "\n",
        "# Simulate an RGB image - 32x32 pixels with 3 color channels\n",
        "image_rgb = np.random.rand(32, 32, 3)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(8, 4)) # 1 row, 2 columns\n",
        "\n",
        "# Display grayscale\n",
        "im_gray = axes[0].imshow(image_gray, cmap='gray') # Use grayscale colormap\n",
        "axes[0].set_title(\"Grayscale Image\")\n",
        "axes[0].axis('off') # Hide axes ticks/labels for images\n",
        "# fig.colorbar(im_gray, ax=axes[0]) # Optional: add colorbar\n",
        "\n",
        "# Display RGB\n",
        "im_rgb = axes[1].imshow(image_rgb) # Default colormap usually works for RGB\n",
        "axes[1].set_title(\"RGB Image\")\n",
        "axes[1].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "TROS-VYG6JgH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. Heatmaps (`plt.imshow()` / `seaborn.heatmap()`)**\n",
        "\n",
        "* **Use Case:** Visualizing confusion matrices, correlation matrices between features. While `imshow` can create basic heatmaps, the `seaborn` library (built on Matplotlib) often provides a more convenient function (`seaborn.heatmap`) specifically for this."
      ],
      "metadata": {
        "id": "JLnEzWws6JgH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulate a confusion matrix (Actual vs Predicted)\n",
        "# Rows: Actual Class 0, 1, 2\n",
        "# Columns: Predicted Class 0, 1, 2\n",
        "conf_matrix = np.array([\n",
        "    [100, 5, 2], # Actual 0: Pred 0, Pred 1, Pred 2\n",
        "    [8, 110, 7], # Actual 1: Pred 0, Pred 1, Pred 2\n",
        "    [1, 4, 95]  # Actual 2: Pred 0, Pred 1, Pred 2\n",
        "])\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(5, 4))\n",
        "im = ax.imshow(conf_matrix, cmap='Blues') # Choose a colormap (e.g., Blues, viridis, magma)\n",
        "\n",
        "# Add labels, title, ticks\n",
        "ax.set_xticks(np.arange(conf_matrix.shape[1]))\n",
        "ax.set_yticks(np.arange(conf_matrix.shape[0]))\n",
        "ax.set_xticklabels(['Pred 0', 'Pred 1', 'Pred 2'])\n",
        "ax.set_yticklabels(['Actual 0', 'Actual 1', 'Actual 2'])\n",
        "ax.set_xlabel(\"Predicted Label\")\n",
        "ax.set_ylabel(\"True Label\")\n",
        "ax.set_title(\"Confusion Matrix\")\n",
        "\n",
        "# Rotate the tick labels and set their alignment.\n",
        "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
        "\n",
        "# Loop over data dimensions and create text annotations.\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        text_color = \"white\" if conf_matrix[i, j] > conf_matrix.max() / 2 else \"black\" # Choose text color based on background\n",
        "        text = ax.text(j, i, conf_matrix[i, j],\n",
        "                       ha=\"center\", va=\"center\", color=text_color)\n",
        "\n",
        "fig.colorbar(im) # Add a colorbar to show the scale\n",
        "fig.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# --- Alternative using Seaborn (often simpler for heatmaps) ---\n",
        "# import seaborn as sns\n",
        "# fig, ax = plt.subplots(figsize=(5, 4))\n",
        "# sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
        "#             xticklabels=['Pred 0', 'Pred 1', 'Pred 2'],\n",
        "#             yticklabels=['Actual 0', 'Actual 1', 'Actual 2'])\n",
        "# ax.set_xlabel(\"Predicted Label\")\n",
        "# ax.set_ylabel(\"True Label\")\n",
        "# ax.set_title(\"Confusion Matrix (Seaborn)\")\n",
        "# plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "6CphJEuG6JgH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. Customization and Saving**\n",
        "\n",
        "* **Labels & Title:** `ax.set_xlabel()`, `ax.set_ylabel()`, `ax.set_title()`\n",
        "* **Legend:** `ax.legend()` (requires `label='...'` in plot commands)\n",
        "* **Axis Limits:** `ax.set_xlim()`, `ax.set_ylim()`\n",
        "* **Grid:** `ax.grid(True)`\n",
        "* **Figure Size:** `plt.figure(figsize=(width, height))` or `fig, ax = plt.subplots(figsize=(width, height))`\n",
        "* **Subplots:** `fig, axes = plt.subplots(nrows, ncols)` allows creating a grid of plots. Access individual plots via `axes[row, col]` or `axes[index]` if 1D.\n",
        "* **Saving:** `plt.savefig('my_plot.png', dpi=300)` saves the *current figure* to a file (various formats like png, pdf, svg supported). `dpi` controls resolution."
      ],
      "metadata": {
        "id": "oqf7ENXE6JgH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example saving a plot\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot([1, 2, 3], [1, 4, 9])\n",
        "ax.set_title(\"Simple Plot to Save\")\n",
        "plt.savefig('simple_plot.png', dpi=150) # Save before plt.show() if running as script\n",
        "# plt.show() # Not strictly needed if only saving"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "OXTPkvAk6JgH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These functions provide a solid foundation for visualizing data and model results throughout the machine learning lifecycle. Remember that libraries like Seaborn build upon Matplotlib to offer higher-level interfaces for specific statistical plot types."
      ],
      "metadata": {
        "id": "S0T_JsN56JgH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"md-recitation\">\n",
        "  Sources\n",
        "  <ol>\n",
        "  <li><a href=\"https://github.com/Christonikos/Dynamic-Risk-Assesment\">https://github.com/Christonikos/Dynamic-Risk-Assesment</a></li>\n",
        "  <li><a href=\"https://forum.knime.com/t/annotated-heatmap-using-python-view-node/66218\">https://forum.knime.com/t/annotated-heatmap-using-python-view-node/66218</a></li>\n",
        "  <li><a href=\"https://github.com/Allorak/pr5\">https://github.com/Allorak/pr5</a></li>\n",
        "  </ol>\n",
        "</div>"
      ],
      "metadata": {
        "id": "t0aeQLL36JgH"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}